Precision = round(precision, 3),
F1 = round(f1, 3)
)
# Print test cm
print(test.cm)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(test.cm), colnames(test.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(test.cm), colnames(test.cm)] <- test.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
print(metrics)
knn.train.true <- train$NEIGHBORHOOD
knn.test.true  <- test$NEIGHBORHOOD
# Raw predictions
train.pred.raw <- predict(mod.knn, train[,-1])
test.pred.raw  <- predict(mod.knn, test[,-1])
# Ensure factor levels are consistent with the original training data
knn.train.predicted <- factor(train.pred.raw, levels = unique(train$NEIGHBORHOOD))
knn.test.predicted  <- factor(test.pred.raw,  levels = unique(train$NEIGHBORHOOD))
# --- Confusion Matrices ---
train.cm <- table(Actual = knn.train.true, Predicted = knn.train.predicted)
test.cm  <- table(Actual = knn.test.true,  Predicted = knn.test.predicted)
# Print matrices
print(train.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(train.cm), colnames(train.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(train.cm), colnames(train.cm)] <- train.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(train.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
# Print test cm
print(test.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(test.cm), colnames(test.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(test.cm), colnames(test.cm)] <- test.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
print(metrics)
# Evaluate RF
rf.train.true <- train$NEIGHBORHOOD
rf.test.true  <- test$NEIGHBORHOOD
# Raw predictions
train.pred.raw <- predict(mod.rf, train[,-1])
test.pred.raw  <- predict(mod.rf, test[,-1])
# Ensure factor levels are consistent with the original training data
rf.train.predicted <- factor(train.pred.raw, levels = unique(train$NEIGHBORHOOD))
rf.test.predicted  <- factor(test.pred.raw,  levels = unique(train$NEIGHBORHOOD))
# --- Confusion Matrices ---
train.cm <- table(Actual = rf.train.true, Predicted = rf.train.predicted)
test.cm  <- table(Actual = rf.test.true,  Predicted = rf.test.predicted)
# Print matrices
print(train.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(train.cm), colnames(train.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(train.cm), colnames(train.cm)] <- train.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(train.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
# Print test cm
print(test.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(test.cm), colnames(test.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(test.cm), colnames(test.cm)] <- test.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
print(metrics)
queens.data <- city.data[city.data$BOROUGH == 'QUEENS', ]
# Filter out zero or extreme sale prices using the Manhattan IQR
queens.clean <- queens.data %>%
filter(SALE.PRICE >= (Q1 - 1.5 * IQR_val) &
SALE.PRICE <= (Q3 + 1.5 * IQR_val)) %>%
filter(SALE.PRICE > 0) %>%
mutate(
NEIGHBORHOOD = as.factor(NEIGHBORHOOD),
BUILDING.CLASS.CATEGORY = as.factor(BUILDING.CLASS.CATEGORY),
LAND.SQUARE.FEET = as.integer(LAND.SQUARE.FEET),
GROSS.SQUARE.FEET = as.integer(GROSS.SQUARE.FEET),
logPrice = log(SALE.PRICE)
)
# Keep only columns used in models
queens.clean2 <- queens.clean %>%
select(all_of(model_columns)) %>%
na.omit()
# --- Step 2: Regression predictions ---
# Predict SALE.PRICE using the Manhattan linear model
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
queens.data <- city.data[city.data$BOROUGH == 'QUEENS', ]
# Filter out zero or extreme sale prices using the Manhattan IQR
queens.clean <- queens.data %>%
filter(SALE.PRICE >= (Q1 - 1.5 * IQR_val) &
SALE.PRICE <= (Q3 + 1.5 * IQR_val)) %>%
filter(SALE.PRICE > 0) %>%
mutate(
NEIGHBORHOOD = as.factor(NEIGHBORHOOD),
BUILDING.CLASS.CATEGORY = as.factor(BUILDING.CLASS.CATEGORY),
LAND.SQUARE.FEET = as.integer(LAND.SQUARE.FEET),
GROSS.SQUARE.FEET = as.integer(GROSS.SQUARE.FEET),
logPrice = log(SALE.PRICE)
)
# Keep all columns used in the regression model (including BUILDING.CLASS.CATEGORY)
queens.clean2 <- queens.clean %>%
select(NEIGHBORHOOD, BUILDING.CLASS.CATEGORY, YEAR.BUILT,
RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET,
GROSS.SQUARE.FEET, SALE.PRICE) %>%
na.omit()
# --- Step 2: Regression predictions ---
# Predict SALE.PRICE using the Manhattan linear model
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
queens.data <- city.data[city.data$BOROUGH == 'QUEENS', ]
# Filter out zero or extreme sale prices using the Manhattan IQR
queens.clean <- queens.data %>%
filter(SALE.PRICE >= (Q1 - 1.5 * IQR_val) &
SALE.PRICE <= (Q3 + 1.5 * IQR_val)) %>%
filter(SALE.PRICE > 0) %>%
mutate(
NEIGHBORHOOD = as.factor(NEIGHBORHOOD),
BUILDING.CLASS.CATEGORY = as.factor(BUILDING.CLASS.CATEGORY),
LAND.SQUARE.FEET = as.integer(LAND.SQUARE.FEET),
GROSS.SQUARE.FEET = as.integer(GROSS.SQUARE.FEET),
logPrice = log(SALE.PRICE)
)
# Keep all columns used in the regression model (including BUILDING.CLASS.CATEGORY)
queens.clean2 <- queens.clean %>%
select(NEIGHBORHOOD, BUILDING.CLASS.CATEGORY, YEAR.BUILT,
RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET,
GROSS.SQUARE.FEET, SALE.PRICE) %>%
na.omit()
# Predict SALE.PRICE using the Manhattan linear model
queens.clean2$pred_sale_price <- predict(lm_log_model,
newdata = queens.clean2 %>% select(-NEIGHBORHOOD))
# Keep all columns used in the regression model (including BUILDING.CLASS.CATEGORY)
queens.clean2 <- queens.clean %>%
select(NEIGHBORHOOD, BUILDING.CLASS.CATEGORY, YEAR.BUILT,
RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET,
GROSS.SQUARE.FEET, SALE.PRICE) %>%
na.omit()
queens.clean2$NEIGHBORHOOD <- factor(queens.clean2$NEIGHBORHOOD,
levels = levels(manhatten_clean$NEIGHBORHOOD))
# Predict SALE.PRICE using the Manhattan linear model
queens.clean2$pred_sale_price <- predict(lm_log_model,
newdata = queens.clean2 %>% select(-NEIGHBORHOOD))
queens.clean2$NEIGHBORHOOD <- factor(queens.clean2$NEIGHBORHOOD,
levels = levels(manhatten_clean$NEIGHBORHOOD))
# Predict SALE.PRICE using the Manhattan linear model
queens.clean2$pred_sale_price <- predict(lm_log_model,
newdata = queens.clean2 %>% select(-NEIGHBORHOOD))
# Predict
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
queens.clean2$BUILDING.CLASS.CATEGORY <- factor(queens.clean2$BUILDING.CLASS.CATEGORY,
levels = levels(manhatten_clean$BUILDING.CLASS.CATEGORY))
# Predict
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
queens.clean2$NEIGHBORHOOD <- factor(queens.clean2$NEIGHBORHOOD,
levels = levels(manhatten_clean$NEIGHBORHOOD))
queens.clean2$BUILDING.CLASS.CATEGORY <- factor(queens.clean2$BUILDING.CLASS.CATEGORY,
levels = levels(manhatten_clean$BUILDING.CLASS.CATEGORY))
# Predict
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
# Map unseen levels to NA
queens.clean2$NEIGHBORHOOD <- factor(queens.clean2$NEIGHBORHOOD,
levels = levels(manhatten_clean$NEIGHBORHOOD))
queens.clean2$BUILDING.CLASS.CATEGORY <- factor(queens.clean2$BUILDING.CLASS.CATEGORY,
levels = levels(manhatten_clean$BUILDING.CLASS.CATEGORY))
# Replace any values not in levels with NA
queens.clean2$NEIGHBORHOOD[is.na(queens.clean2$NEIGHBORHOOD)] <- NA
queens.clean2$BUILDING.CLASS.CATEGORY[is.na(queens.clean2$BUILDING.CLASS.CATEGORY)] <- NA
# Predict
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
lm_numeric <- lm(SALE.PRICE ~ YEAR.BUILT + RESIDENTIAL.UNITS + COMMERCIAL.UNITS + LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data = manhatten_clean)
summary(lm_numeric)
# Predict
queens.clean2$pred_sale_price <- predict(lm_log_model, newdata = queens.clean2)
# Predict
queens.clean2$pred_sale_price <- predict(lm_numeric, newdata = queens.clean2)
queens.data <- city.data[city.data$BOROUGH == 'QUEENS', ]
# Filter out zero or extreme sale prices using the Manhattan IQR
queens.clean <- queens.data %>%
filter(SALE.PRICE >= (Q1 - 1.5 * IQR_val) &
SALE.PRICE <= (Q3 + 1.5 * IQR_val)) %>%
filter(SALE.PRICE > 0) %>%
mutate(
NEIGHBORHOOD = as.factor(NEIGHBORHOOD),
BUILDING.CLASS.CATEGORY = as.factor(BUILDING.CLASS.CATEGORY),
LAND.SQUARE.FEET = as.integer(LAND.SQUARE.FEET),
GROSS.SQUARE.FEET = as.integer(GROSS.SQUARE.FEET),
logPrice = log(SALE.PRICE)
)
# Keep all columns used in the regression model (including BUILDING.CLASS.CATEGORY)
queens.clean2 <- queens.clean %>%
select(NEIGHBORHOOD, BUILDING.CLASS.CATEGORY, YEAR.BUILT,
RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET,
GROSS.SQUARE.FEET, SALE.PRICE) %>%
na.omit()
lm_numeric <- lm(SALE.PRICE ~ YEAR.BUILT + RESIDENTIAL.UNITS + COMMERCIAL.UNITS + LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data = manhatten_clean)
summary(lm_numeric)
# Predict
queens.clean2$pred_sale_price <- predict(lm_numeric, newdata = queens.clean2)
ggplot(queens.clean2, aes(x = pred_sale_price, y = SALE.PRICE)) +
geom_point(alpha = 0.6, color = "blue") +
geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
labs(
title = "Queens: Predicted vs Actual SALE.PRICE",
x = "Predicted SALE.PRICE (from Manhattan model)",
y = "Actual SALE.PRICE"
) +
theme_minimal()
queens.clean2$residuals <- queens.clean2$SALE.PRICE - queens.clean2$pred_sale_price
ggplot(queens.clean2, aes(x = pred_sale_price, y = residuals)) +
geom_point(alpha = 0.6, color = "darkgreen") +
geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
labs(
title = "Queens: Residuals vs Fitted Values",
x = "Predicted SALE.PRICE (Fitted Values)",
y = "Residuals"
) +
theme_minimal()
# True labels
knn.queens.true <- queens.clean2$NEIGHBORHOOD
# Raw predictions
knn.queens.pred <- factor(predict(mod.knn, queens.clean2[,-1]),
levels = unique(train$NEIGHBORHOOD))
rf.queens.pred  <- factor(predict(mod.rf, queens.clean2[,-1]),
levels = unique(train$NEIGHBORHOOD))
# --- Step 4: Confusion matrices ---
# KNN
knn.cm <- table(Actual = knn.queens.true, Predicted = knn.queens.pred)
all_classes <- union(rownames(knn.cm), colnames(knn.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(knn.cm), colnames(knn.cm)] <- knn.cm
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
knn_accuracy <- sum(diag_vals) / sum(cm_full)
knn_precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
knn_recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
knn_f1        <- ifelse(is.na(knn_precision) | is.na(knn_recall) |
(knn_precision + knn_recall) == 0,
NA, 2 * knn_precision * knn_recall / (knn_precision + knn_recall))
knn_metrics <- data.frame(
Class = all_classes,
Recall = round(knn_recall, 3),
Precision = round(knn_precision, 3),
F1 = round(knn_f1, 3)
)
# RF
rf.cm <- table(Actual = knn.queens.true, Predicted = rf.queens.pred)
all_classes <- union(rownames(rf.cm), colnames(rf.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(rf.cm), colnames(rf.cm)] <- rf.cm
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
rf_accuracy <- sum(diag_vals) / sum(cm_full)
rf_precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
rf_recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
rf_f1        <- ifelse(is.na(rf_precision) | is.na(rf_recall) |
(rf_precision + rf_recall) == 0,
NA, 2 * rf_precision * rf_recall / (rf_precision + rf_recall))
rf_metrics <- data.frame(
Class = all_classes,
Recall = round(rf_recall, 3),
Precision = round(rf_precision, 3),
F1 = round(rf_f1, 3)
)
cat("\nKNN metrics on Queens:\n")
print(knn_metrics)
cat("\nOverall Accuracy:", knn_accuracy, "\n")
cat("\nRF metrics on Queens:\n")
print(rf_metrics)
cat("\nOverall Accuracy:", rf_accuracy, "\n")
cm_full
cm_full
mod.knn2 <- train(NEIGHBORHOOD~YEAR.BUILT + RESIDENTIAL.UNITS + COMMERCIAL.UNITS + SALE.PRICE, data=train, method="knn", preProcess = c("center", "scale"), metric=metric)
knn2.train.true <- train$NEIGHBORHOOD
knn2.test.true  <- test$NEIGHBORHOOD
# Raw predictions
train.pred.raw <- predict(mod.knn2, train[,-1])
test.pred.raw  <- predict(mod.knn2, test[,-1])
# Ensure factor levels are consistent with the original training data
knn2.train.predicted <- factor(train.pred.raw, levels = unique(train$NEIGHBORHOOD))
knn2.test.predicted  <- factor(test.pred.raw,  levels = unique(train$NEIGHBORHOOD))
# --- Confusion Matrices ---
train.cm <- table(Actual = knn2.train.true, Predicted = knn2.train.predicted)
test.cm  <- table(Actual = knn2.test.true,  Predicted = knn2.test.predicted)
# Print matrices
print(train.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(train.cm), colnames(train.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(train.cm), colnames(train.cm)] <- train.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(train.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
# Print test cm
print(test.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(test.cm), colnames(test.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(test.cm), colnames(test.cm)] <- test.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
print(metrics)
knn.train.true <- train$NEIGHBORHOOD
knn.test.true  <- test$NEIGHBORHOOD
# Raw predictions
train.pred.raw <- predict(mod.knn, train[,-1])
test.pred.raw  <- predict(mod.knn, test[,-1])
# Ensure factor levels are consistent with the original training data
knn.train.predicted <- factor(train.pred.raw, levels = unique(train$NEIGHBORHOOD))
knn.test.predicted  <- factor(test.pred.raw,  levels = unique(train$NEIGHBORHOOD))
# --- Confusion Matrices ---
train.cm <- table(Actual = knn.train.true, Predicted = knn.train.predicted)
test.cm  <- table(Actual = knn.test.true,  Predicted = knn.test.predicted)
# Print matrices
print(train.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(train.cm), colnames(train.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(train.cm), colnames(train.cm)] <- train.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(train.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
# Print test cm
print(test.cm)
# Pad confusion matrix if missing predicted levels
all_classes <- union(rownames(test.cm), colnames(test.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(test.cm), colnames(test.cm)] <- test.cm
# Now safely compute diag, precision, recall, f1
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
accuracy <- sum(diag_vals) / sum(test.cm)
accuracy
precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
f1        <- ifelse(is.na(precision) | is.na(recall) | (precision + recall) == 0,
NA, 2 * precision * recall / (precision + recall))
# Combine into dataframe
metrics <- data.frame(
Class = all_classes,
Recall = round(recall, 3),
Precision = round(precision, 3),
F1 = round(f1, 3)
)
print(metrics)
knn2.queens.pred <- factor(predict(mod.knn2, queens.clean2[,-1]),
levels = unique(train$NEIGHBORHOOD))
knn2.cm <- table(Actual = knn.queens.true, Predicted = knn2.queens.pred)
all_classes <- union(rownames(knn2.cm), colnames(knn2.cm))
cm_full <- matrix(0, nrow = length(all_classes), ncol = length(all_classes),
dimnames = list(all_classes, all_classes))
cm_full[rownames(knn2.cm), colnames(knn2.cm)] <- knn2.cm
cm_full
diag_vals <- diag(cm_full)
rowsums <- rowSums(cm_full)
colsums <- colSums(cm_full)
knn2_accuracy <- sum(diag_vals) / sum(cm_full)
knn2_precision <- ifelse(colsums == 0, NA, diag_vals / colsums)
knn2_recall    <- ifelse(rowsums == 0, NA, diag_vals / rowsums)
knn2_f1        <- ifelse(is.na(knn2_precision) | is.na(knn2_recall) |
(knn2_precision + knn2_recall) == 0,
NA, 2 * knn2_precision * knn2_recall / (knn2_precision + knn2_recall))
knn2_metrics <- data.frame(
Class = all_classes,
Recall = round(knn2_recall, 3),
Precision = round(knn2_precision, 3),
F1 = round(knn2_f1, 3)
)
cat("\nKNN metrics on Queens:\n")
print(knn_metrics)
cat("\nOverall Accuracy:", knn_accuracy, "\n")
cat("\nRF metrics on Queens:\n")
print(rf_metrics)
cat("\nOverall Accuracy:", rf_accuracy, "\n")
cat("\nKNN2 metrics on Queens:\n")
print(knn2_metrics)
cat("\nOverall Accuracy:", knn2_accuracy, "\n")
